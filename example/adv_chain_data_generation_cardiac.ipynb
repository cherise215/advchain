{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Finding effective transformation for data augmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "# sys.path.append('path/to/advchain')\n",
    "# sys.path.append('/vol/biomedic3/cc215/Project/advchain')\n",
    "# import advchain\n",
    "%matplotlib inline\n",
    "sns.set()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# # sys.path.append('path/to/advchain')\n",
    "sys.path.append('/vol/biomedic3/cc215/Project/advchain')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from advchain.augmentor.adv_bias import AdvBias\n",
    "# from advchain.augmentor.adv_morph import AdvMorph\n",
    "# from advchain.augmentor.adv_noise import AdvNoise\n",
    "# from advchain.augmentor.adv_affine import AdvAffine\n",
    "# from advchain.augmentor import ComposeAdversarialTransformSolver\n",
    "\n",
    "from advchain.common.utils import random_chain,load_image_label\n",
    "from advchain.common.loss import cross_entropy_2D\n",
    "from advchain.common.vis import plot_warped_grid, plot_noise,plot_bias_field,plot_image,plot_general\n",
    "from  advchain.models.unet import get_unet_model"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'adv_transformation_base'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7654f6082721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0madvchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_bias\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdvBias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# from advchain.augmentor.adv_morph import AdvMorph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from advchain.augmentor.adv_noise import AdvNoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from advchain.augmentor.adv_affine import AdvAffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from advchain.augmentor import ComposeAdversarialTransformSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/biomedic3/cc215/Project/advchain/advchain/augmentor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0madv_transformation_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0madv_affine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0madv_bias\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0madv_morph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0madv_noise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'adv_transformation_base'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cuda.empty_cache()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_path ='./data/cardiac/img.nrrd'\n",
    "label_path ='./data/cardiac/seg.nrrd'\n",
    "slice_id = 5\n",
    "crop_size=(192,192)\n",
    "cropped_image,cropped_label =load_image_label (image_path,label_path,slice_id=slice_id,crop_size=crop_size)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Preprocessing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "font_size=12\n",
    "plt.subplot(121)\n",
    "plt.title('image',size=font_size)\n",
    "plt.imshow(cropped_image,cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(cropped_label,cmap='gray')\n",
    "plt.title('manual label',size=font_size)\n",
    "plt.axis('off')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2 Load a segmentation model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "use_gpu=True\n",
    "model = get_unet_model(num_classes=4,model_path='/vol/biomedic3/cc215/Project/DeformADA/result/ACDC_Segmentation/multi_class_baseline/three_shot/pretrained_models/affine_elastic_intensity_opt/0_cval_0/best/checkpoints/UNet_16$SAX$_Segmentation.pth',model_arch='UNet_16')\n",
    "\n",
    "if use_gpu: model = model.cuda()\n",
    "model.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cropped_image,cropped_label =load_image_label(image_path,label_path,slice_id=8,crop_size=crop_size)\n",
    "font_size=12\n",
    "image_tensor = torch.from_numpy(cropped_image[np.newaxis,np.newaxis,:,:]).float()\n",
    "label_tensor = torch.from_numpy(cropped_image[np.newaxis,:,:]).long()\n",
    "if use_gpu: \n",
    "    image_tensor = image_tensor.cuda()\n",
    "    label_tensor = label_tensor.cuda()\n",
    "image_tensor.requires_grad=False\n",
    "init_output = model(image_tensor)\n",
    "pred_map = init_output.max(1)[1].cpu().data.numpy()\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title('image',size=font_size)\n",
    "plt.imshow(cropped_image,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(cropped_label,cmap='gray')\n",
    "plt.title('manual label',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(pred_map[0],cmap='gray')\n",
    "plt.title('init pred',size=font_size)\n",
    "plt.axis('off')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.1 Set up basic transformations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bs=1\n",
    "im_ch=1\n",
    "augmentor_bias= AdvBias(\n",
    "                 config_dict={'epsilon':0.3,\n",
    "                 'control_point_spacing':[crop_size[0]//2,crop_size[1]//2],\n",
    "                 'downscale':2,\n",
    "                 'data_size':(bs,im_ch,crop_size[0],crop_size[1]),\n",
    "                 'interpolation_order':3,\n",
    "                 'init_mode':'random',\n",
    "                 'space':'log'},debug=False)\n",
    "\n",
    "                 \n",
    "\n",
    "augmentor_noise= AdvNoise( config_dict={'epsilon':1,\n",
    "                'xi':1e-6,\n",
    "                 'data_size':(bs,im_ch,crop_size[0],crop_size[1])},\n",
    "                 debug=False)\n",
    "    \n",
    "augmentor_affine= AdvAffine( config_dict={\n",
    "                 'rot':15/180,\n",
    "                 'scale_x':0.2,\n",
    "                 'scale_y':0.2,\n",
    "                 'shift_x':0.1,\n",
    "                 'shift_y':0.1,\n",
    "                 'data_size':(bs,im_ch,crop_size[0],crop_size[1]),\n",
    "                 'forward_interp':'bilinear',\n",
    "                 'backward_interp':'bilinear'},\n",
    "                 debug=False)\n",
    "\n",
    "augmentor_morph= AdvMorph(\n",
    "                config_dict=\n",
    "                {'epsilon':1.5,\n",
    "                 'data_size':(bs,im_ch,crop_size[0],crop_size[1]),\n",
    "                 'vector_size':[crop_size[0]//8,crop_size[1]//8],\n",
    "                 'interpolator_mode':'bilinear'\n",
    "                 }, \n",
    "                 debug=False)\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.2. Set up a solver for adversarial data augmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## keep model fixed, set up a solver\n",
    "model.eval()\n",
    "transformation_chain = [augmentor_affine,augmentor_noise,augmentor_bias,augmentor_morph]\n",
    "solver = ComposeAdversarialTransformSolver(\n",
    "        chain_of_transforms=transformation_chain,\n",
    "        divergence_types = ['mse','contour'], ### you can also change it to 'kl'.\n",
    "        divergence_weights=[1.0,0.5],\n",
    "        use_gpu= True,\n",
    "        debug=True,\n",
    "        if_norm_image=False\n",
    "       )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.1. Start learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# random initialization\n",
    "solver.init_random_transformation()\n",
    "rand_transformed_image = solver.forward(image_tensor.detach().clone())\n",
    "rand_predict = model.forward(rand_transformed_image)\n",
    "warp_back_rand_predict= solver.predict_backward(rand_predict)\n",
    "\n",
    "rand_bias = augmentor_bias.bias_field\n",
    "rand_noise = augmentor_noise.param\n",
    "rand_dxy,rand_morph = augmentor_morph.get_deformation_displacement_field(-augmentor_morph.param)\n",
    "\n",
    "loss = solver.adversarial_training(\n",
    "        data=image_tensor,model=model,\n",
    "        n_iter=1,\n",
    "        lazy_load=[True]*4, ## if set to true, it will use the previous sampled random bias field as initialization.\n",
    "        optimize_flags=[True,True,True,True],power_iteration=False)\n",
    "\n",
    "adv_bias= augmentor_bias.bias_field\n",
    "adv_noise = augmentor_noise.param\n",
    "adv_dxy,adv_morph = augmentor_morph.get_deformation_displacement_field(-augmentor_morph.param)\n",
    "adv_transformed_image = solver.forward(image_tensor.detach().clone())\n",
    "adv_predict = model.forward(adv_transformed_image)\n",
    "warp_back_adv_predict= solver.predict_backward(adv_predict)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.2. Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.set(font_scale=10)\n",
    "rand_transformed_image_numpy=rand_transformed_image.cpu().data.numpy()[0,0]\n",
    "adv_transformed_image_numpy=adv_transformed_image.cpu().data.numpy()[0,0]\n",
    "\n",
    "rand_predict_numpy=warp_back_rand_predict.max(1)[1].cpu().data.numpy()[0]\n",
    "adv_predict_numpy=warp_back_adv_predict.max(1)[1].cpu().data.numpy()[0]\n",
    "\n",
    "rand_before_warped_predict_numpy=rand_predict.max(1)[1].cpu().data.numpy()[0]\n",
    "adv_before_warped_predict_numpy=adv_predict.max(1)[1].cpu().data.numpy()[0]\n",
    "\n",
    "rand_bias_numpy=rand_bias.cpu().data.numpy()[0,0]\n",
    "adv_bias_numpy=adv_bias.cpu().data.numpy()[0,0]\n",
    "\n",
    "rand_noise_numpy=rand_noise.cpu().data.numpy()[0,0]\n",
    "adv_noise_numpy=adv_noise.cpu().data.numpy()[0,0]\n",
    "\n",
    "rand_morph_grid = rand_morph.permute(0,3,1,2)[0].data.cpu().numpy()\n",
    "adv_morph_grid = adv_morph.permute(0,3,1,2)[0].data.cpu().numpy()\n",
    "rand_deformed_image =augmentor_morph.transform(image_tensor,rand_dxy).cpu().data.numpy()[0,0]\n",
    "adv_deformed_image =augmentor_morph.transform(image_tensor,adv_dxy).cpu().data.numpy()[0,0]\n",
    "\n",
    "gird_interval = 5\n",
    "vis_deforme_image=False ## turn it on to see deformed image\n",
    "fig,axes = plt.subplots(2,9,figsize=(22,8))\n",
    "plot_image(cropped_image,ax = axes[0,0],title='Input',font_size=font_size)\n",
    "plot_noise(rand_noise_numpy,ax = axes[0,1],title='+Rand noise',font_size=font_size)\n",
    "plot_bias_field(rand_bias_numpy,ax= axes[0,2],title='+Rand bias')\n",
    "plot_warped_grid(rand_morph_grid, ax=axes[0,3],bg_img=rand_deformed_image*vis_deforme_image, interval=gird_interval, title=\"+Rand morph\", fontsize=font_size, linewidth=0.5,show=True)\n",
    "plot_image(rand_transformed_image_numpy, ax=axes[0,4],title=\"+Rand affine\", font_size=font_size)\n",
    "plot_image(pred_map[0],ax = axes[0,5],title='Before',font_size=font_size)\n",
    "plot_image(rand_before_warped_predict_numpy,ax = axes[0,6],title='After',font_size=font_size)\n",
    "plot_image(rand_predict_numpy,ax = axes[0,7],title='After${}^{*}$',font_size=font_size)\n",
    "plot_general(rand_predict_numpy-pred_map[0],ax = axes[0,8],title='Diff',font_size=font_size,cmap='seismic')\n",
    "\n",
    "plot_image(cropped_image,title='Input',ax = axes[1,0],font_size=font_size)\n",
    "plot_noise(adv_noise_numpy,ax = axes[1,1],title='+Adv noise',font_size=font_size)\n",
    "plot_bias_field(adv_bias_numpy,ax= axes[1,2],title='+Adv bias')\n",
    "plot_warped_grid(adv_morph_grid, ax=axes[1,3],bg_img=adv_deformed_image*vis_deforme_image, interval=gird_interval, title=\"+Adv morph\", fontsize=font_size, linewidth=0.5,show=True)\n",
    "plot_image(adv_transformed_image_numpy, ax=axes[1,4],title=\"+Adv affine\", font_size=font_size)\n",
    "plot_image(pred_map[0],title='Before',ax = axes[1,5],font_size=font_size)\n",
    "plot_image(adv_before_warped_predict_numpy,ax = axes[1,6],title='After',font_size=font_size)\n",
    "plot_image(adv_predict_numpy,title='After${}^{*}$',ax = axes[1,7],font_size=font_size)\n",
    "plot_general(adv_predict_numpy-pred_map[0],ax = axes[1,8],title='Diff',font_size=font_size,cmap='seismic')\n",
    "plt.savefig('./test_chain_image.png')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Example: plug-in adversarial training code to enhance cardiac segmentation network training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## now you can simply learn effective adversarial transformation on-the-fly to enhance training. a sample code will be like the following\n",
    "## pseudo code for model optimization at one iteration: \n",
    "\n",
    "## sample a chain\n",
    "transformation_family = [augmentor_noise,augmentor_bias,augmentor_morph,augmentor_affine]\n",
    "\n",
    "one_chain = random_chain(transformation_family.copy())[0]\n",
    "\n",
    "print ('sample a chain:')\n",
    "[print ('-> '+tr.get_name()) for tr in one_chain]\n",
    "\n",
    "solver = ComposeAdversarialTransformSolver(\n",
    "        chain_of_transforms=one_chain,\n",
    "        divergence_types = ['mse','contour'], ### you can also change it to 'mse' for mean squared error loss\n",
    "        divergence_weights=[1.0,0.5],\n",
    "        use_gpu= True,\n",
    "        debug=True, ## turn off debugging information when training your model\n",
    "       )\n",
    "\n",
    "## compute consistency loss\n",
    "reg_loss = solver.adversarial_training(\n",
    "        data = image_tensor,model=model, init_output=init_output.detach().clone(),\n",
    "        n_iter = 1,\n",
    "        lazy_load = [False]*len(one_chain), \n",
    "        optimize_flags = [True]*len(one_chain),  ## you can also turn off adversarial training for one particular transformation\n",
    "        step_sizes = None)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "model.train()\n",
    "model.zero_grad()\n",
    "init_output = model(image_tensor)\n",
    "\n",
    "## compute supervised loss\n",
    "supervised_loss = cross_entropy_2D (init_output,label_tensor)\n",
    "lamda=1\n",
    "total_loss = supervised_loss+lamda*reg_loss\n",
    "total_loss.backward()\n",
    "optimizer.step() \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('new_benchmark': conda)"
  },
  "interpreter": {
   "hash": "62ce74b4455b0951965d257e46d77b8a88c22ef06fc866aa0e581269e0bc2661"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}